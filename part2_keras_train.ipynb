{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDate : 2019, APRIL\\nAuthor : Apiwit Theeraporn\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Date : 2019, APRIL\n",
    "Author : Apiwit Theeraporn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# use tensorflow backend\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "import cv2\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display,Image,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-deterministic input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'processed_images/'\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 215, 240\n",
    "\n",
    "# Batch_size to train\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train\n",
    "nb_epoch = 20  \n",
    "\n",
    "# Total number of convolutional filters to use ~ batch\n",
    "nb_filters = 8\n",
    "\n",
    "# Max pooling\n",
    "nb_pool = 2\n",
    "\n",
    "# Size of convolution kernel\n",
    "nb_conv = 5\n",
    "\n",
    "kernel_size = (nb_conv,nb_conv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-deterministic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display : This method instaed of cv2.imageShow\n",
    "def iPythonDisplay(img_arr, fmt='jpeg'):\n",
    "    with BytesIO() as output:\n",
    "        with PIL.Image.fromarray(img_arr) as img:\n",
    "            img.save(output,format=fmt);\n",
    "        img_byte = output.getvalue()\n",
    "    display(Image(data=img_byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras load images from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 4 classes.\n",
      "Found 8 images belonging to 4 classes.\n",
      "all classes :  {'buff': 0, 'fist': 1, 'luv': 2, 'rock': 3}\n",
      "got total class = 4\n"
     ]
    }
   ],
   "source": [
    "# flow_from_directory will first load data from it's config\n",
    "\"\"\"\n",
    "The function will run after the image is resized and augmented. \n",
    "The function should take one argument: an image (Numpy tensor with rank 3), \n",
    "and should output a Numpy tensor with the same shape.\n",
    "\"\"\"\n",
    "datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2 # reserve some data for validation\n",
    ")\n",
    "\n",
    "# number of channels\n",
    "# For 'grayscale' use 1 ,and for 'rgb' images use 3\n",
    "img_channels = 1\n",
    "\n",
    "# import first then transform\n",
    "processed_train_generator = datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    batch_size=batch_size,\n",
    "    target_size = (img_rows, img_cols),\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode = 'grayscale',\n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "processed_valid_generator = datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    batch_size=batch_size,\n",
    "    target_size = (img_rows, img_cols),\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode = 'grayscale',\n",
    "    subset='validation',\n",
    ")\n",
    "\n",
    "\n",
    "nb_classes = len(processed_train_generator.class_indices)\n",
    "print('all classes : ',processed_valid_generator.class_indices)\n",
    "print('got total class =',len(processed_train_generator.class_indices));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 211, 236, 8)       208       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 211, 236, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 207, 232, 8)       1608      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 207, 232, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 103, 116, 8)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 103, 116, 8)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 95584)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               12234880  \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 12,237,212\n",
      "Trainable params: 12,237,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(\n",
    "    nb_filters, \n",
    "    kernel_size,\n",
    "    input_shape=(img_rows, img_cols,img_channels)))\n",
    "    # input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\"\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv)))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/8 [==========>...................] - ETA: 5s - loss: 1.5943 - acc: 0.2500Epoch 1/20\n",
      "8/8 [==============================] - 7s 877ms/step - loss: 1.3663 - acc: 0.4531 - val_loss: 1.0714 - val_acc: 0.7500\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.6292 - acc: 0.8594 - val_loss: 0.4944 - val_acc: 0.7500\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.1039 - acc: 0.9844 - val_loss: 0.2631 - val_acc: 0.8750\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 6s 732ms/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.2556 - val_acc: 0.8750\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 7s 834ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3936 - val_acc: 0.8750\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.8750\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 6s 732ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.3687 - val_acc: 0.8750\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.3362 - val_acc: 0.8750\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 8.1848e-05 - acc: 1.0000 - val_loss: 0.3356 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ab1f0b8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=processed_train_generator.batch_size\n",
    "\n",
    "STAMP = 'best_gesture_iteration'\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=5)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "        processed_train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        verbose=1,\n",
    "        validation_data=processed_valid_generator,\n",
    "        use_multiprocessing = True,\n",
    "        workers = 2, #CPU 4 cores,\n",
    "        callbacks= [early_stopping, model_checkpoint]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict data ex. in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "# from keras.models import load_model\n",
    "# model = load_model('best_gesture_iteration.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 311ms/step\n",
      "all classes :  {'buff': 0, 'fist': 1, 'luv': 2, 'rock': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict_generator(\n",
    "    processed_valid_generator, \n",
    "    steps=None, \n",
    "    callbacks=None, \n",
    "    workers=2, \n",
    "    use_multiprocessing=True, \n",
    "    verbose=1)\n",
    "\n",
    "print('all classes : ',processed_valid_generator.class_indices)\n",
    "np.round(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
